{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sky mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('paht/to/your/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_sequence_id = \"0058\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision.ops import box_convert\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from glob import glob\n",
    "\n",
    "# Grounding DINO\n",
    "import groundingdino.datasets.transforms as T\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util import box_ops\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "from segment_anything import build_sam, SamPredictor \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup(args):\n",
    "    # ======================== Load Grounding DINO model ========================\n",
    "    print(colored('Load Grounding DINO model', 'green'))\n",
    "    def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "        cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "        args = SLConfig.fromfile(cache_config_file) \n",
    "        model = build_model(args)\n",
    "        args.device = device\n",
    "\n",
    "        cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "        checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "        log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "        print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "        _ = model.eval()\n",
    "        return model   \n",
    "\n",
    "    # Use this command for evaluate the Grounding DINO model\n",
    "    # Or you can download the model by yourself\n",
    "    ckpt_repo_id = \"your/GroundingDINO\"\n",
    "    ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "    ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
    "    global groundingdino_model \n",
    "    groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)\n",
    "\n",
    "    # ======================== Load Segment Anything model ========================\n",
    "    print(colored('Load SAM model', 'green'))\n",
    "    sam = build_sam(checkpoint=args.sam_checkpoint)\n",
    "    sam.cuda()\n",
    "    global sam_predictor\n",
    "    sam_predictor = SamPredictor(sam)\n",
    "\n",
    "image_filename_to_cam = lambda x: int(x.split('.')[0][-1])\n",
    "image_filename_to_frame = lambda x: int(x.split('.')[0][:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_to_mask_dict(masks_dict, mask_path):\n",
    "    basename = os.path.basename(mask_path)\n",
    "    cam = image_filename_to_cam(basename)\n",
    "    frame = image_filename_to_frame(basename)\n",
    "    mask = cv2.imread(mask_path) \n",
    "    if frame not in masks_dict:\n",
    "        masks_dict[frame] = [None] * 3 # FRONT_LEFT, FRONT, FRONT_RIGHT 1, 0, 2\n",
    "    if cam == 1:\n",
    "        masks_dict[frame][0] = mask\n",
    "    elif cam == 0:\n",
    "        masks_dict[frame][1] = mask\n",
    "    elif cam == 2:\n",
    "        masks_dict[frame][2] = mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_with_text_prompt(datadir, BOX_TRESHOLD, TEXT_TRESHOLD, ignore_exists):\n",
    "    save_dir = os.path.join(datadir, 'sky_mask')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    image_dir = os.path.join(datadir, 'images')\n",
    "    image_files = glob(image_dir + \"/*.jpg\") \n",
    "    image_files += glob(image_dir + \"/*.png\")\n",
    "    image_files = sorted(image_files)\n",
    "    \n",
    "    masks_dict = dict()\n",
    "    for image_path in tqdm(image_files):\n",
    "        image_base_name = os.path.basename(image_path)\n",
    "        output_mask = os.path.join(save_dir, image_base_name)\n",
    "                        \n",
    "        if os.path.exists(output_mask) and ignore_exists:\n",
    "            add_to_mask_dict(masks_dict, output_mask)\n",
    "            print(f'{output_mask} exists, skip')\n",
    "            continue\n",
    "        \n",
    "        cam = image_filename_to_cam(image_base_name)\n",
    "        box_threshold = BOX_TRESHOLD[cam]\n",
    "        \n",
    "        image_source, image = load_image(image_path)\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=groundingdino_model, \n",
    "            image=image, \n",
    "            caption='sky', \n",
    "            box_threshold=box_threshold, \n",
    "            text_threshold=TEXT_TRESHOLD\n",
    "        )\n",
    "\n",
    "        print(f'detecting {boxes.shape[0]} boxed of sky in {image_path}, box_threshold: {box_threshold}, logits: {logits}')\n",
    "        if boxes.shape[0] != 0:\n",
    "            H, W, _ = image_source.shape\n",
    "            boxes = box_ops.box_cxcywh_to_xyxy(boxes)\n",
    "            boxes_xyxy = boxes * torch.Tensor([W, H, W, H])\n",
    "            # assume that the box prompt for sky should be close to the top edge of the image\n",
    "            #  --------------  top edge \n",
    "            # | x ----       |\n",
    "            # | |    |       |\n",
    "            # |  ----x       |\n",
    "            #  --------------\n",
    "            boxes_mask = boxes_xyxy[:, 1] < 100 # 100 pixels\n",
    "            boxes_xyxy = boxes_xyxy[boxes_mask]\n",
    "        else:\n",
    "            boxes_xyxy = []\n",
    "        \n",
    "        num_boxes = len(boxes_xyxy)\n",
    "\n",
    "        if num_boxes == 0:                \n",
    "            mask = np.zeros_like(image_source[..., 0])\n",
    "        else:\n",
    "            sam_predictor.set_image(image_source)\n",
    "            transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).cuda()\n",
    "            masks, _, _ = sam_predictor.predict_torch(\n",
    "                        point_coords = None,\n",
    "                        point_labels = None,\n",
    "                        boxes = transformed_boxes,\n",
    "                        multimask_output = False,\n",
    "                    )\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            mask_final = torch.zeros_like(masks[0, 0]).bool()\n",
    "            for mask in masks[:, 0]:\n",
    "                mask_final = mask_final | mask.bool()\n",
    "                \n",
    "            mask = mask_final.cpu().numpy()\n",
    "            \n",
    "        cv2.imwrite(output_mask, mask * 255)\n",
    "        add_to_mask_dict(masks_dict, output_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.datadir = f'data/dair-v2x/exp/{specified_sequence_id}_0_original'\n",
    "        self.box_threshold = [0.3]\n",
    "        self.text_threshold = 0.25\n",
    "        self.ignore_exists = ''\n",
    "        self.sam_checkpoint = 'path/to/your/GroundingDINO/weights/sam_vit_h_4b8939.pth'\n",
    "        \n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert isinstance(args.box_threshold, list)\n",
    "if len(args.box_threshold) == 1:\n",
    "    box_threshold = [args.box_threshold[0]] * 5\n",
    "else:\n",
    "    assert len(args.box_threshold) == 5\n",
    "    box_threshold = args.box_threshold\n",
    "print('box_threshold: ', box_threshold)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_with_text_prompt(\n",
    "    datadir=args.datadir, \n",
    "    BOX_TRESHOLD=box_threshold,\n",
    "    TEXT_TRESHOLD=args.text_threshold,\n",
    "    ignore_exists=args.ignore_exists,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ego mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=args.datadir\n",
    "BOX_TRESHOLD=box_threshold\n",
    "TEXT_TRESHOLD=args.text_threshold\n",
    "ignore_exists=args.ignore_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dir = os.path.join(datadir, 'ego_mask')  \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "image_dir = os.path.join(datadir, 'images')\n",
    "image_files = glob(image_dir + \"/*.jpg\") \n",
    "image_files += glob(image_dir + \"/*.png\")\n",
    "image_files = sorted(image_files)\n",
    "\n",
    "masks_dict = dict()\n",
    "\n",
    "i =0\n",
    "\n",
    "for image_path in tqdm(image_files):\n",
    "    image_base_name = os.path.basename(image_path)\n",
    "    output_mask = os.path.join(save_dir, image_base_name)\n",
    "    \n",
    "    cam = image_filename_to_cam(image_base_name)\n",
    "    box_threshold = BOX_TRESHOLD[cam]\n",
    "    \n",
    "    image_source, image = load_image(image_path)\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=groundingdino_model, \n",
    "        image=image, \n",
    "        caption='car',  \n",
    "        box_threshold=box_threshold, \n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "\n",
    "    print(f'detecting {boxes.shape[0]} boxed of car in {image_path}, box_threshold: {box_threshold}, logits: {logits}')\n",
    "    if boxes.shape[0] != 0:\n",
    "        H, W, _ = image_source.shape\n",
    "        boxes = box_ops.box_cxcywh_to_xyxy(boxes)\n",
    "        boxes_xyxy = boxes * torch.Tensor([W, H, W, H])\n",
    "        boxes_mask = boxes_xyxy[:, 3] > (H - 100) \n",
    "        boxes_xyxy = boxes_xyxy[boxes_mask]\n",
    "    else:\n",
    "        boxes_xyxy = []\n",
    "    \n",
    "    num_boxes = len(boxes_xyxy)\n",
    "\n",
    "    if num_boxes == 0:                \n",
    "        mask = np.zeros_like(image_source[..., 0])\n",
    "    else:\n",
    "        sam_predictor.set_image(image_source)\n",
    "        transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).cuda()\n",
    "        masks, _, _ = sam_predictor.predict_torch(\n",
    "                    point_coords = None,\n",
    "                    point_labels = None,\n",
    "                    boxes = transformed_boxes,\n",
    "                    multimask_output = False,\n",
    "                )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        mask_final = torch.zeros_like(masks[0, 0]).bool()\n",
    "        for mask in masks[:, 0]:\n",
    "            mask_final = mask_final | mask.bool()\n",
    "            \n",
    "        mask = mask_final.cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(cv2.cvtColor(image_source, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Ego Mask\")\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show() \n",
    "    \n",
    "    cv2.imwrite(output_mask, mask * 255)\n",
    "    \n",
    "    i+=1\n",
    "    if i ==15:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cruise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
