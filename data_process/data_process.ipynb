{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_list = ['0000',\n",
    " '0001',\n",
    " '0002',\n",
    " '0003',\n",
    " '0004',\n",
    " '0005',\n",
    " '0007',\n",
    " '0008',\n",
    " '0010',\n",
    " '0014',\n",
    " '0015',\n",
    " '0016',\n",
    " '0017',\n",
    " '0018',\n",
    " '0020',\n",
    " '0021',\n",
    " '0022',\n",
    " '0023',\n",
    " '0025',\n",
    " '0029',\n",
    " '0030',\n",
    " '0032',\n",
    " '0033',\n",
    " '0034',\n",
    " '0035',\n",
    " '0036',\n",
    " '0037',\n",
    " '0040',\n",
    " '0041',\n",
    " '0042',\n",
    " '0047',\n",
    " '0048',\n",
    " '0049',\n",
    " '0050',\n",
    " '0052',\n",
    " '0054',\n",
    " '0055',\n",
    " '0056',\n",
    " '0057',\n",
    " '0058',\n",
    " '0059',\n",
    " '0060',\n",
    " '0061',\n",
    " '0062',\n",
    " '0063',\n",
    " '0066',\n",
    " '0068',\n",
    " '0070',\n",
    " '0071',\n",
    " '0072',\n",
    " '0073',\n",
    " '0075',\n",
    " '0077',\n",
    " '0078',\n",
    " '0079',\n",
    " '0080',\n",
    " '0081',\n",
    " '0082',\n",
    " '0084',\n",
    " '0085',\n",
    " '0086',\n",
    " '0087',\n",
    " '0088',\n",
    " '0089',\n",
    " '0092',\n",
    " '0093',\n",
    " '0094']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_sequence_id = '0000'  # Set the sequence_id you want to process.\n",
    "source_path = \"/mnt/zhangsn/data/V2X-Seq-SPD\"  # Original address of the dataset\n",
    "des_path = \"/mnt/zhangsn/data/V2X-Seq-SPD-Processed\"\n",
    "\n",
    "# output_dir = \"/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0017_0_original_all_cooperative_with_cooperative_pointcloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_number(number, width=6):\n",
    "    return str(number).zfill(width)\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_extrinsics_lidar_to_novatel(json_data):\n",
    "    rotation = np.array(json_data['transform']['rotation'])\n",
    "    translation = np.array(json_data['transform']['translation']).reshape(3, 1)\n",
    "    extrinsic_matrix = np.hstack((rotation, translation))\n",
    "    return extrinsic_matrix\n",
    "\n",
    "def get_extrinsics(json_data):\n",
    "    rotation = np.array(json_data['rotation'])\n",
    "    translation = np.array(json_data['translation']).reshape(3, 1)\n",
    "    extrinsic_matrix = np.hstack((rotation, translation))\n",
    "    return extrinsic_matrix\n",
    "\n",
    "def get_extrinsics_compute_lidar_to_world(lidar_to_novatel_data, novatel_to_world_data):\n",
    "    lidar_to_novatel = get_extrinsics_lidar_to_novatel(lidar_to_novatel_data)\n",
    "    novatel_to_world = get_extrinsics(novatel_to_world_data)\n",
    "    lidar_to_world = np.dot(novatel_to_world, np.vstack((lidar_to_novatel, [0, 0, 0, 1])))\n",
    "    return lidar_to_world\n",
    "\n",
    "def get_intrinsics(json_data):\n",
    "    cam_K = np.array(json_data['cam_K']).reshape(3, 3)\n",
    "    return cam_K\n",
    "\n",
    "def pad_poses(p):\n",
    "    \"\"\"Pad [..., 3, 4] pose matrices with a homogeneous bottom row [0,0,0,1].\"\"\"\n",
    "    bottom = np.broadcast_to([0, 0, 0, 1.], p[..., :1, :4].shape)\n",
    "    return np.concatenate([p[..., :3, :4], bottom], axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{source_path}/cooperative/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "cooperative_data_info_df = pd.DataFrame(data_info_data)\n",
    "cooperative_filtered_df = cooperative_data_info_df[cooperative_data_info_df['infrastructure_sequence'] == specified_sequence_id]\n",
    "\n",
    "\n",
    "with open(f'{source_path}/infrastructure-side/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "infrastructure_data_info_df = pd.DataFrame(data_info_data)\n",
    "\n",
    "infrastructure_filtered_df = infrastructure_data_info_df[infrastructure_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "infrastructure_filtered_df = infrastructure_filtered_df.loc[infrastructure_filtered_df['frame_id'].isin(cooperative_filtered_df['infrastructure_frame'])]\n",
    "\n",
    "\n",
    "with open(f'{source_path}/vehicle-side/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "vehicle_data_info_df = pd.DataFrame(data_info_data)\n",
    "vehicle_filtered_df = vehicle_data_info_df[vehicle_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "vehicle_filtered_df = vehicle_filtered_df.loc[vehicle_filtered_df['frame_id'].isin(cooperative_filtered_df['vehicle_frame'])]\n",
    "\n",
    "\n",
    "infrastructure_calib_camera_intrinsic_paths = infrastructure_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "vehicle_calib_camera_intrinsic_paths = vehicle_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "car_list_infrastructure = [os.path.splitext(os.path.basename(path))[0] for path in infrastructure_calib_camera_intrinsic_paths]\n",
    "car_list_vehicle = [os.path.splitext(os.path.basename(path))[0] for path in vehicle_calib_camera_intrinsic_paths]\n",
    "vehicle_filtered_df.reset_index(drop=True, inplace=True)\n",
    "infrastructure_filtered_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy corresponding files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# vehicle_source_path = f'{source_path}/vehicle-side'\n",
    "# road_source_path = f'{source_path}/infrastructure-side'\n",
    "\n",
    "# move_file_list = ['images']\n",
    "# image_file_list = ['VEHICLE', 'ROAD']\n",
    "\n",
    "# destination_folder = f'{des_path}/{specified_sequence_id}_0_original'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_class in move_file_list:\n",
    "#     destination_image_folder = os.path.join(destination_folder, file_class)\n",
    "#     os.makedirs(destination_image_folder,exist_ok=True)\n",
    "#     if file_class == 'images':\n",
    "#         for image_class in image_file_list:\n",
    "#             if image_class =='VEHICLE':\n",
    "#                 for index, row in vehicle_filtered_df.iterrows():\n",
    "#                     _source_path = os.path.join(vehicle_source_path,row['image_path'])\n",
    "#                     destination_path = os.path.join(destination_image_folder, f'{get_padded_number(index)}_0.jpg')\n",
    "#                     shutil.copy(_source_path, destination_path)\n",
    "\n",
    "#                 print(\"Car image file copy completed.\")\n",
    "#             elif image_class =='ROAD':\n",
    "#                 for index, row in infrastructure_filtered_df.iterrows():\n",
    "#                     _source_path = os.path.join(road_source_path,row['image_path'])\n",
    "#                     destination_path = os.path.join(destination_image_folder, f'{get_padded_number(index)}_1.jpg')\n",
    "#                     shutil.copy(_source_path, destination_path)\n",
    "#                 print(\"Road image file copy completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# image_dir = f\"data/dair-v2x/exp/{specified_sequence_id}_0_original/images\"\n",
    "# image_filenames_all = sorted(glob(os.path.join(image_dir, '*.jpg')))\n",
    "# image_filename_to_cam = lambda x: int(x.split('.')[0][-1])\n",
    "# for image_filename in image_filenames_all:\n",
    "#     image_basename = os.path.basename(image_filename)\n",
    "#     cam = image_filename_to_cam(image_basename)\n",
    "#     os.makedirs(f'data/dair-v2x/exp/{specified_sequence_id}_1_single/images', exist_ok=True)\n",
    "#     destination_path = f'data/dair-v2x/exp/{specified_sequence_id}_1_single/images/{image_basename}'\n",
    "#     if cam ==0:\n",
    "#         shutil.copy(image_filename, destination_path)\n",
    "# image_dir = f\"data/dair-v2x/exp/{specified_sequence_id}_0_original/sky_mask\"\n",
    "# image_filenames_all = sorted(glob(os.path.join(image_dir, '*.jpg')))\n",
    "# image_filename_to_cam = lambda x: int(x.split('.')[0][-1])\n",
    "# for image_filename in image_filenames_all:\n",
    "#     image_basename = os.path.basename(image_filename)\n",
    "#     cam = image_filename_to_cam(image_basename)\n",
    "#     os.makedirs(f'data/dair-v2x/exp/{specified_sequence_id}_1_single/sky_mask', exist_ok=True)\n",
    "#     destination_path = f'data/dair-v2x/exp/{specified_sequence_id}_1_single/sky_mask/{image_basename}'\n",
    "#     if cam ==0:\n",
    "#         shutil.copy(image_filename, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation file generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cooperative-view annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_list = car_list_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def convert_annotations(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    track_info_path = os.path.join(output_dir, 'track_info.txt')\n",
    "    track_camera_vis_path = os.path.join(output_dir, 'track_camera_vis.json')\n",
    "\n",
    "    track_info_lines = ['frame_id track_id object_class alpha box_height box_width box_length box_center_x box_center_y box_center_z box_heading speed']\n",
    "    track_camera_vis = {}\n",
    "    \n",
    "    for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "        \n",
    "        annotations = read_json_file(os.path.join(source_path,'cooperative', 'label', car_list_vehicle[idx] +'.json'))\n",
    "        frame_id = idx\n",
    "\n",
    "        for ann in annotations:\n",
    "            track_id = ann['track_id']\n",
    "            object_class = ann['type']\n",
    "            alpha = ann['alpha']\n",
    "            box_height = ann['3d_dimensions']['h']\n",
    "            box_width = ann['3d_dimensions']['w']\n",
    "            box_length = ann['3d_dimensions']['l']\n",
    "            box_center_x = ann['3d_location']['x']\n",
    "            box_center_y = ann['3d_location']['y']\n",
    "            box_center_z = ann['3d_location']['z']\n",
    "            box_heading = ann['rotation']\n",
    "            speed = 0  \n",
    "\n",
    "            track_info_lines.append(f'{frame_id} {track_id} {object_class} {alpha} {box_height} {box_width} {box_length} {box_center_x} {box_center_y} {box_center_z} {box_heading} {speed}')\n",
    "\n",
    "            if track_id not in track_camera_vis:\n",
    "                track_camera_vis[track_id] = {}\n",
    "                \n",
    "            if ann[\"from_side\"] =='coop':\n",
    "                if ann['occluded_state'] == 1 or  ann['occluded_state'] == 2:\n",
    "                    track_camera_vis[track_id][frame_id] = [1]\n",
    "                else:\n",
    "                    track_camera_vis[track_id][frame_id] = list(range(2))\n",
    "            elif ann[\"from_side\"]==\"veh\":\n",
    "                if ['occluded_state'] == 2 :\n",
    "                    track_camera_vis[track_id][frame_id] = []\n",
    "                else:    \n",
    "                    track_camera_vis[track_id][frame_id] = [0]\n",
    "            elif ann[\"from_side\"]=='inf':\n",
    "                if ['occluded_state'] == 2 :\n",
    "                    track_camera_vis[track_id][frame_id] = []\n",
    "                else:\n",
    "                    track_camera_vis[track_id][frame_id] = [1]\n",
    "\n",
    "    with open(track_info_path, 'w') as f:\n",
    "        f.write('\\n'.join(track_info_lines))\n",
    "\n",
    "    with open(track_camera_vis_path, 'w') as f:\n",
    "        json.dump(track_camera_vis, f, indent=2)\n",
    "\n",
    "# output_dir = f'{des_path}/{specified_sequence_id}_0_original/track' \n",
    "output_dir = \"/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0034_0_original_test\"\n",
    "\n",
    "convert_annotations(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-view annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import glob\n",
    "\n",
    "# def convert_annotations(output_dir):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     track_info_path = os.path.join(output_dir, 'track_info.txt')\n",
    "#     track_camera_vis_path = os.path.join(output_dir, 'track_camera_vis.json')\n",
    "\n",
    "#     track_info_lines = ['frame_id track_id object_class alpha box_height box_width box_length box_center_x box_center_y box_center_z box_heading speed']\n",
    "#     track_camera_vis = {}\n",
    "    \n",
    "#     for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "        \n",
    "#         annotations = read_json_file(os.path.join(source_path,'cooperative', 'label', car_list_vehicle[idx] +'.json'))\n",
    "#         frame_id = idx\n",
    "\n",
    "#         for ann in annotations:\n",
    "#             if ann[\"veh_track_id\"] !=\"-1\":\n",
    "                \n",
    "#                 track_id = ann['track_id']\n",
    "#                 object_class = ann['type']\n",
    "#                 alpha = ann['alpha']\n",
    "#                 box_height = ann['3d_dimensions']['h']\n",
    "#                 box_width = ann['3d_dimensions']['w']\n",
    "#                 box_length = ann['3d_dimensions']['l']\n",
    "#                 box_center_x = ann['3d_location']['x']\n",
    "#                 box_center_y = ann['3d_location']['y']\n",
    "#                 box_center_z = ann['3d_location']['z']\n",
    "#                 box_heading = ann['rotation']\n",
    "#                 speed = 0  \n",
    "\n",
    "#                 track_info_lines.append(f'{frame_id} {track_id} {object_class} {alpha} {box_height} {box_width} {box_length} {box_center_x} {box_center_y} {box_center_z} {box_heading} {speed}')\n",
    "\n",
    "#                 if track_id not in track_camera_vis:\n",
    "#                     track_camera_vis[track_id] = {}\n",
    "                    \n",
    "#                 track_camera_vis[track_id][frame_id] = [0]\n",
    "                \n",
    "\n",
    "#     with open(track_info_path, 'w') as f:\n",
    "#         f.write('\\n'.join(track_info_lines))\n",
    "\n",
    "#     with open(track_camera_vis_path, 'w') as f:\n",
    "#         json.dump(track_camera_vis, f, indent=2)\n",
    "\n",
    "\n",
    "# output_dir = f'{des_path}/{specified_sequence_id}_1_single/track' \n",
    "# convert_annotations(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to remove the ego vehicle's label at the roadside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because retaining the annotation box of the ego vehicle during the training process can lead to data processing errors, the annotation box of the ego vehicle needs to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = f'{des_path}/{specified_sequence_id}_0_original/track/track_info.txt'\n",
    "# output_file = f'{des_path}/{specified_sequence_id}_0_original/track/track_info_temp.txt'\n",
    "\n",
    "# with open(input_file, 'r', encoding='utf-8') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "# filtered_lines = []\n",
    "# for line in lines:\n",
    "#     elements = line.split()\n",
    "#     if len(elements) < 2 or elements[1] != '005686':\n",
    "#         '''\n",
    "#         0000:002834\n",
    "#         0015:007570\n",
    "#         0022:003821\n",
    "#         0066:005686\n",
    "#         '''\n",
    "#         filtered_lines.append(line)\n",
    "\n",
    "# with open(output_file, 'w', encoding='utf-8') as file:\n",
    "#     file.writelines(filtered_lines)\n",
    "\n",
    "# print(\n",
    "#     f\"Processing completed, deleted all rows with the second position as xxxx, and the result saved to '{output_file}'。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point cloud file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 0it [00:00, ?it/s]\n",
      "Loading data: 195it [00:00, 992.77it/s]\n"
     ]
    }
   ],
   "source": [
    "car_list = car_list_vehicle\n",
    "\n",
    "for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "    vehicle_lidar_to_novatel_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_novatel', car_list_vehicle[idx] +'.json'))\n",
    "    infrastructure_camera_intrinsics_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'camera_intrinsic',car_list_infrastructure[idx]+'.json'))\n",
    "    vehicle_camera_intrinsics_json = read_json_file(os.path.join(source_path,'vehicle-side', 'calib', 'camera_intrinsic', car_list_vehicle[idx] +'.json'))\n",
    "    infrastructure_lidar_to_camera_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_camera',car_list_infrastructure[idx]+'.json'))\n",
    "    vehicle_lidar_to_camera_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_camera', car_list_vehicle[idx] +'.json'))\n",
    "    break\n",
    "    \n",
    "lidar2cam = get_extrinsics(vehicle_lidar_to_camera_json)\n",
    "lidar2cam_padded = pad_poses(lidar2cam)\n",
    "cam2lidar = np.linalg.inv(lidar2cam_padded)\n",
    "\n",
    "car_list = car_list_vehicle\n",
    "camera_w2cs = dict()\n",
    "camera_lidar2ws = dict()\n",
    "camera_lidar2camera = dict()\n",
    "world2lidars = []\n",
    "lidar2worlds = []\n",
    "\n",
    "for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "    infrastructure_camera_intrinsics_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'camera_intrinsic',car_list_infrastructure[idx]+'.json'))\n",
    "    infrastructure_lidar_to_camera_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_camera',car_list_infrastructure[idx]+'.json'))\n",
    "    infrastructure_lidar_to_world_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_world',car_list_infrastructure[idx]+'.json'))\n",
    "\n",
    "    vehicle_camera_intrinsics_json = read_json_file(os.path.join(source_path,'vehicle-side', 'calib', 'camera_intrinsic', car_list_vehicle[idx] +'.json'))\n",
    "    vehicle_lidar_to_camera_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_camera', car_list_vehicle[idx] +'.json'))\n",
    "    vehicle_lidar_to_novatel_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_novatel', car_list_vehicle[idx] +'.json')) \n",
    "    vehicle_novatel_to_world_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'novatel_to_world', car_list_vehicle[idx] +'.json')) \n",
    "\n",
    "    Ks = np.array([get_intrinsics(infrastructure_camera_intrinsics_json), get_intrinsics(vehicle_camera_intrinsics_json)]) \n",
    "    lidar2cam = np.array([get_extrinsics(infrastructure_lidar_to_camera_json),get_extrinsics(vehicle_lidar_to_camera_json)])\n",
    "    lidar2world = np.array([get_extrinsics(infrastructure_lidar_to_world_json), get_extrinsics_compute_lidar_to_world(vehicle_lidar_to_novatel_json, vehicle_novatel_to_world_json)])\n",
    "    \n",
    "    novatel_to_world = get_extrinsics(vehicle_novatel_to_world_json)\n",
    "    \n",
    "    novatel_to_world_padded = pad_poses(novatel_to_world)\n",
    "\n",
    "    lidar2cam_padded = pad_poses(lidar2cam)\n",
    "    lidar2world_padded = pad_poses(lidar2world)\n",
    "    lidar2worlds.append(lidar2world_padded)\n",
    "    \n",
    "    world2lidar = np.linalg.inv(lidar2world_padded)\n",
    "    world2lidars.append(world2lidar)\n",
    "    \n",
    "    cam2lidar = np.linalg.inv(lidar2cam_padded)\n",
    "    \n",
    "    c2w = lidar2world_padded @ cam2lidar\n",
    "    w2c = np.linalg.inv(c2w)\n",
    "    \n",
    "    cam_road2cam_car = w2c[1] @ c2w[0]\n",
    "    cam_road2lidar_car = cam2lidar[1] @ cam_road2cam_car\n",
    "    lidar_car2cam_road = np.linalg.inv(cam_road2lidar_car)\n",
    "    \n",
    "    if idx not in camera_lidar2camera:\n",
    "        camera_lidar2camera[idx] = {} \n",
    "    if idx not in camera_w2cs:\n",
    "        camera_w2cs[idx] = {} \n",
    "    \n",
    "    camera_lidar2camera[idx]['cam0'] = lidar2cam_padded[1]\n",
    "    camera_lidar2camera[idx]['cam1'] = lidar_car2cam_road  \n",
    "\n",
    "camera_intrinsics = {\n",
    "    \"cam0\": Ks[1],\n",
    "    \"cam1\": Ks[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooperative pointcloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        # 检查文件是否存在\n",
    "        if os.path.exists(file_path):\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "            print(f\"文件 '{file_path}' 已成功删除\")\n",
    "        else:\n",
    "            print(f\"文件 '{file_path}' 不存在\")\n",
    "    except Exception as e:\n",
    "        print(f\"删除文件时发生错误: {str(e)}\")\n",
    "        \n",
    "        \n",
    "import shutil\n",
    "\n",
    "def delete_directory(dir_path):\n",
    "    try:\n",
    "        if os.path.exists(dir_path):\n",
    "            # 删除目录及其所有内容\n",
    "            shutil.rmtree(dir_path)\n",
    "            print(f\"目录 '{dir_path}' 已成功删除\")\n",
    "        else:\n",
    "            print(f\"目录 '{dir_path}' 不存在\")\n",
    "    except Exception as e:\n",
    "        print(f\"删除目录时发生错误: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 195it [00:06, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0000_0_original\n",
      "文件 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0000_0_original/pointcloud_cooperative.npz' 已成功删除\n",
      "Processing LiDAR data done...\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "point_xyz_vehicle_combineds= []\n",
    "\n",
    "for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "    pcd_infrastructure = o3d.io.read_point_cloud(os.path.join(source_path,'infrastructure-side', \"velodyne\", car_list_infrastructure[idx] + \".pcd\"))\n",
    "    point_infrastructure = np.asarray(pcd_infrastructure.points) \n",
    "    intensities_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    elongation_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    timestamp_pts_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    point_data_infrastructure = np.hstack((point_infrastructure, intensities_infrastructure, elongation_infrastructure, timestamp_pts_infrastructure))\n",
    "    point_xyz_infrastructure, intensities_infrastructure, elongation_infrastructure, timestamp_pts_infrastructure = np.split(point_data_infrastructure, [3, 4, 5], axis=1)\n",
    "    point_xyz_world_infrastructure = (np.pad(point_xyz_infrastructure, ((0, 0), (0, 1)), constant_values=1) @ lidar2worlds[idx][0].T)[:, :3]\n",
    "    # point_xyz_world_infrastructure = (np.pad(point_xyz_infrastructure, ((0, 0), (0, 1)), constant_values=1) @ lidar2world_padded[0].T)[:, :3]\n",
    "\n",
    "    pcd_vehicle = o3d.io.read_point_cloud(os.path.join(source_path,'vehicle-side' , \"velodyne\", car_list_vehicle[idx] + \".pcd\"))\n",
    "    point_vehicle = np.asarray(pcd_vehicle.points) \n",
    "    intensities_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    elongation_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    timestamp_pts_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    point_data_vehicle = np.hstack((point_vehicle, intensities_vehicle, elongation_vehicle, timestamp_pts_vehicle))\n",
    "    point_xyz_vehicle, intensities_vehicle, elongation_vehicle, timestamp_pts_vehicle = np.split(point_data_vehicle, [3, 4, 5], axis=1)\n",
    "    point_xyz_world_vehicle = (np.pad(point_xyz_vehicle, ((0, 0), (0, 1)), constant_values=1) @ lidar2worlds[idx][1].T)[:, :3]\n",
    "    # point_xyz_world_vehicle = (np.pad(point_xyz_vehicle, ((0, 0), (0, 1)), constant_values=1) @ lidar2world_padded[1].T)[:, :3]\n",
    "    \n",
    "    point_xyz_world_combined = np.vstack((point_xyz_world_infrastructure, point_xyz_world_vehicle))\n",
    "    \n",
    "    world2lidar = world2lidars[idx]\n",
    "    point_xyz_vehicle_combined = (np.pad(point_xyz_world_combined, ((0, 0), (0, 1)), constant_values=1) @ world2lidar[1].T)[:, :3]\n",
    "    point_xyz_vehicle_combineds.append(point_xyz_vehicle_combined)\n",
    "\n",
    "def load_pcd(file_path):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def project_to_camera(pts_3d_camera, intrinsic, camera_id):\n",
    "    img_width = 1920\n",
    "    img_height  = 1080\n",
    "    z = pts_3d_camera[:, 2]\n",
    "    valid_mask = z > 1e-6 \n",
    "    \n",
    "    pts_3d_camera = pts_3d_camera[:,:3]\n",
    "    \n",
    "    pts_2d_camera = np.dot(pts_3d_camera[valid_mask], intrinsic.T)\n",
    "    \n",
    "    pts_2d_camera[:, 0] /= pts_2d_camera[:, 2]\n",
    "    pts_2d_camera[:, 1] /= pts_2d_camera[:, 2]\n",
    "    \n",
    "    camera_projection = np.zeros((pts_2d_camera.shape[0], 6), dtype=np.int16)\n",
    "    camera_projection[:, 0] = camera_id \n",
    "    camera_projection[:, 1] = np.clip(np.round(pts_2d_camera[:, 0]), 0, img_width-1).astype(np.int16) \n",
    "    camera_projection[:, 2] = np.clip(np.round(pts_2d_camera[:, 1]), 0, img_height-1).astype(np.int16) \n",
    "    \n",
    "    return camera_projection, valid_mask\n",
    "\n",
    "def process_lidar_data( camera_intrinsics, camera_lidar2camera, output_dir):\n",
    "    pts_3d_all = dict()\n",
    "    pts_2d_all = dict()\n",
    "    \n",
    "    for frame_idx, frame_id in enumerate(car_list_vehicle):\n",
    "    \n",
    "        pts_3d_lidar = point_xyz_vehicle_combineds[frame_idx]\n",
    "        \n",
    "        points_homogeneous = np.hstack((pts_3d_lidar, np.ones((pts_3d_lidar.shape[0], 1))))\n",
    "\n",
    "        pts_3d_frame = []\n",
    "        pts_2d_frame = []\n",
    "        \n",
    "        for cam_idx, (cam_name, intrinsic) in enumerate(camera_intrinsics.items()):\n",
    "            \n",
    "            pts_3d_homo = points_homogeneous @ camera_lidar2camera[frame_idx][cam_name].T\n",
    "            pts_3d_camera = pts_3d_homo[:, :3] / pts_3d_homo[:, 3].reshape(-1, 1)  # 归一化 \n",
    "            \n",
    "            camera_projection, valid_mask = project_to_camera(pts_3d_camera, intrinsic, cam_idx)\n",
    "            \n",
    "            pts_3d_frame.append(pts_3d_lidar[valid_mask]) \n",
    "            pts_2d_frame.append(camera_projection)\n",
    "        \n",
    "        if pts_3d_frame and pts_2d_frame:\n",
    "            pts_3d_all[frame_idx] = np.concatenate(pts_3d_frame, axis=0)\n",
    "            pts_2d_all[frame_idx] = np.concatenate(pts_2d_frame, axis=0)\n",
    "    \n",
    "    np.savez_compressed(os.path.join(output_dir, 'pointcloud_cooperative.npz'), \n",
    "                        pointcloud=pts_3d_all, \n",
    "                        camera_projection=pts_2d_all)\n",
    "    print(\"Processing LiDAR data done...\")\n",
    "\n",
    "output_dir = f\"{des_path}/{specified_sequence_id}_0_original\"\n",
    "# output_dir = output_dir\n",
    "print(output_dir)\n",
    "\n",
    "delete_file(output_dir + '/pointcloud_cooperative.npz')\n",
    "process_lidar_data( camera_intrinsics, camera_lidar2camera, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-side pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 195it [00:19,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0000_0_original/pointcloud.npz' 已成功删除\n",
      "Processing LiDAR data done...\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "point_xyz_vehicle_combineds= []\n",
    "\n",
    "for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "    pcd_infrastructure = o3d.io.read_point_cloud(os.path.join(source_path,'infrastructure-side', \"velodyne\", car_list_infrastructure[idx] + \".pcd\"))\n",
    "    point_infrastructure = np.asarray(pcd_infrastructure.points) \n",
    "    intensities_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    elongation_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    timestamp_pts_infrastructure = np.zeros((point_infrastructure.shape[0], 1))\n",
    "    point_data_infrastructure = np.hstack((point_infrastructure, intensities_infrastructure, elongation_infrastructure, timestamp_pts_infrastructure))\n",
    "    point_xyz_infrastructure, intensities_infrastructure, elongation_infrastructure, timestamp_pts_infrastructure = np.split(point_data_infrastructure, [3, 4, 5], axis=1)\n",
    "    point_xyz_world_infrastructure = (np.pad(point_xyz_infrastructure, ((0, 0), (0, 1)), constant_values=1) @ lidar2worlds[idx][0].T)[:, :3]\n",
    "\n",
    "    pcd_vehicle = o3d.io.read_point_cloud(os.path.join(source_path,'vehicle-side' , \"velodyne\", car_list_vehicle[idx] + \".pcd\"))\n",
    "    point_vehicle = np.asarray(pcd_vehicle.points) \n",
    "    intensities_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    elongation_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    timestamp_pts_vehicle = np.zeros((point_vehicle.shape[0], 1))\n",
    "    point_data_vehicle = np.hstack((point_vehicle, intensities_vehicle, elongation_vehicle, timestamp_pts_vehicle))\n",
    "    point_xyz_vehicle, intensities_vehicle, elongation_vehicle, timestamp_pts_vehicle = np.split(point_data_vehicle, [3, 4, 5], axis=1)\n",
    "    point_xyz_world_vehicle = (np.pad(point_xyz_vehicle, ((0, 0), (0, 1)), constant_values=1) @ lidar2worlds[idx][1].T)[:, :3]\n",
    "    \n",
    "    point_xyz_world_combined = np.vstack((point_xyz_world_infrastructure))\n",
    "    \n",
    "    world2lidar = world2lidars[idx]\n",
    "    point_xyz_vehicle_combined = (np.pad(point_xyz_world_combined, ((0, 0), (0, 1)), constant_values=1) @ world2lidar[1].T)[:, :3]\n",
    "    point_xyz_vehicle_combineds.append(point_xyz_vehicle_combined)\n",
    "\n",
    "def load_pcd(file_path):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def project_to_camera(pts_3d_camera, intrinsic, camera_id):\n",
    "    img_width = 1920\n",
    "    img_height  = 1080\n",
    "    z = pts_3d_camera[:, 2]\n",
    "    valid_mask = z > 1e-6 \n",
    "    \n",
    "    pts_3d_camera = pts_3d_camera[:,:3]\n",
    "    \n",
    "    pts_2d_camera = np.dot(pts_3d_camera[valid_mask], intrinsic.T)\n",
    "    \n",
    "    pts_2d_camera[:, 0] /= pts_2d_camera[:, 2]\n",
    "    pts_2d_camera[:, 1] /= pts_2d_camera[:, 2]\n",
    "    \n",
    "    camera_projection = np.zeros((pts_2d_camera.shape[0], 6), dtype=np.int16)\n",
    "    camera_projection[:, 0] = camera_id \n",
    "    camera_projection[:, 1] = np.clip(np.round(pts_2d_camera[:, 0]), 0, img_width-1).astype(np.int16) \n",
    "    camera_projection[:, 2] = np.clip(np.round(pts_2d_camera[:, 1]), 0, img_height-1).astype(np.int16) \n",
    "    \n",
    "    return camera_projection, valid_mask\n",
    "\n",
    "def process_lidar_data( camera_intrinsics, camera_lidar2camera, output_dir):\n",
    "    pts_3d_all = dict()\n",
    "    pts_2d_all = dict()\n",
    "    \n",
    "    for frame_idx, frame_id in enumerate(car_list_vehicle):\n",
    "    \n",
    "        pts_3d_lidar = point_xyz_vehicle_combineds[frame_idx]\n",
    "        \n",
    "        points_homogeneous = np.hstack((pts_3d_lidar, np.ones((pts_3d_lidar.shape[0], 1))))\n",
    "\n",
    "        pts_3d_frame = []\n",
    "        pts_2d_frame = []\n",
    "        \n",
    "        for cam_idx, (cam_name, intrinsic) in enumerate(camera_intrinsics.items()):\n",
    "            # import pdb; pdb.set_trace()\n",
    "            pts_3d_homo = points_homogeneous @ camera_lidar2camera[frame_idx][cam_name].T\n",
    "            pts_3d_camera = pts_3d_homo[:, :3] / pts_3d_homo[:, 3].reshape(-1, 1)  # 归一化 \n",
    "            camera_projection, valid_mask = project_to_camera(pts_3d_camera, intrinsic, cam_idx)\n",
    "            \n",
    "            pts_3d_frame.append(pts_3d_lidar[valid_mask]) \n",
    "            pts_2d_frame.append(camera_projection)\n",
    "        \n",
    "        if pts_3d_frame and pts_2d_frame:\n",
    "            pts_3d_all[frame_idx] = np.concatenate(pts_3d_frame, axis=0)\n",
    "            pts_2d_all[frame_idx] = np.concatenate(pts_2d_frame, axis=0)\n",
    "    \n",
    "    np.savez_compressed(os.path.join(output_dir, 'pointcloud_inf.npz'), \n",
    "                        pointcloud=pts_3d_all, \n",
    "                        camera_projection=pts_2d_all)\n",
    "    print(\"Processing LiDAR data done...\")\n",
    "\n",
    "delete_file(output_dir + '/pointcloud.npz')\n",
    "# output_dir = f\"/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0022_0_original_all_multi_lidar\"\n",
    "\n",
    "process_lidar_data( camera_intrinsics, camera_lidar2camera, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LiDAR data done...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def load_pcd(file_path):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def project_to_camera(pts_3d_camera, intrinsic, camera_id):\n",
    "    img_width = 1920\n",
    "    img_height  = 1080\n",
    "    z = pts_3d_camera[:, 2]\n",
    "    valid_mask = z > 1e-6 \n",
    "    \n",
    "    pts_3d_camera = pts_3d_camera[:,:3]\n",
    "    \n",
    "    pts_2d_camera = np.dot(pts_3d_camera[valid_mask], intrinsic.T)\n",
    "    \n",
    "    pts_2d_camera[:, 0] /= pts_2d_camera[:, 2]\n",
    "    pts_2d_camera[:, 1] /= pts_2d_camera[:, 2]\n",
    "    \n",
    "    camera_projection = np.zeros((pts_2d_camera.shape[0], 6), dtype=np.int16)\n",
    "    camera_projection[:, 0] = camera_id  \n",
    "    camera_projection[:, 1] = np.clip(np.round(pts_2d_camera[:, 0]), 0, img_width-1).astype(np.int16)  \n",
    "    camera_projection[:, 2] = np.clip(np.round(pts_2d_camera[:, 1]), 0, img_height-1).astype(np.int16) \n",
    "    \n",
    "    return camera_projection, valid_mask\n",
    "\n",
    "def process_lidar_data(seq_dir, camera_intrinsics, camera_lidar2camera, output_dir):\n",
    "    \n",
    "    pts_3d_all = dict()\n",
    "    pts_2d_all = dict()\n",
    "    \n",
    "    for frame_idx, frame_id in enumerate(car_list_vehicle):\n",
    "        \n",
    "        pcd_file = os.path.join(seq_dir, frame_id) + '.pcd'\n",
    "        pts_3d_lidar = load_pcd(pcd_file)\n",
    "        \n",
    "        pts_3d_lidar = pts_3d_lidar[:, :3]\n",
    "        \n",
    "        points_homogeneous = np.hstack((pts_3d_lidar, np.ones((pts_3d_lidar.shape[0], 1))))\n",
    "\n",
    "        pts_3d_frame = []\n",
    "        pts_2d_frame = []\n",
    "        \n",
    "        for cam_idx, (cam_name, intrinsic) in enumerate(camera_intrinsics.items()):\n",
    "            pts_3d_homo = points_homogeneous @ camera_lidar2camera[frame_idx][cam_name].T\n",
    "            pts_3d_camera = pts_3d_homo[:, :3] / pts_3d_homo[:, 3].reshape(-1, 1)  # 归一化 \n",
    "            camera_projection, valid_mask = project_to_camera(pts_3d_camera, intrinsic, cam_idx)\n",
    "            \n",
    "            pts_3d_frame.append(pts_3d_lidar[valid_mask]) \n",
    "            pts_2d_frame.append(camera_projection)\n",
    "        \n",
    "        if pts_3d_frame and pts_2d_frame: \n",
    "            pts_3d_all[frame_idx] = np.concatenate(pts_3d_frame, axis=0)\n",
    "            pts_2d_all[frame_idx] = np.concatenate(pts_2d_frame, axis=0)\n",
    "    \n",
    "    np.savez_compressed(os.path.join(output_dir, 'pointcloud_veh.npz'), \n",
    "                        pointcloud=pts_3d_all, \n",
    "                        camera_projection=pts_2d_all)\n",
    "    print(\"Processing LiDAR data done...\")\n",
    "\n",
    "\n",
    "seq_dir = f\"{source_path}/vehicle-side/velodyne\"\n",
    "# output_dir = f\"{des_path}/{specified_sequence_id}_0_original\"\n",
    "# output_dir = output_dir\n",
    "\n",
    "process_lidar_data(seq_dir, camera_intrinsics, camera_lidar2camera, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate lidar depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0000_0_original/lidar_depth' 已成功删除\n"
     ]
    }
   ],
   "source": [
    "delete_directory(output_dir + '/lidar_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/zhangsn/code/street-gs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全用单端的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from lib.utils.img_utils import visualize_depth_numpy\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "image_filename_to_cam = lambda x: int(x.split('.')[0][-1])\n",
    "image_filename_to_frame = lambda x: int(x.split('.')[0][:6])\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_extrinsics_lidar_to_novatel(json_data):\n",
    "    rotation = np.array(json_data['transform']['rotation'])\n",
    "    translation = np.array(json_data['transform']['translation']).reshape(3, 1)\n",
    "    extrinsic_matrix = np.hstack((rotation, translation))\n",
    "    return extrinsic_matrix\n",
    "\n",
    "def get_extrinsics(json_data):\n",
    "    rotation = np.array(json_data['rotation'])\n",
    "    translation = np.array(json_data['translation']).reshape(3, 1)\n",
    "    extrinsic_matrix = np.hstack((rotation, translation))\n",
    "    return extrinsic_matrix\n",
    "\n",
    "def get_extrinsics_compute_lidar_to_world(lidar_to_novatel_data, novatel_to_world_data):\n",
    "    lidar_to_novatel = get_extrinsics_lidar_to_novatel(lidar_to_novatel_data)\n",
    "    novatel_to_world = get_extrinsics(novatel_to_world_data)\n",
    "    lidar_to_world = np.dot(novatel_to_world, np.vstack((lidar_to_novatel, [0, 0, 0, 1])))\n",
    "    \n",
    "    return lidar_to_world\n",
    "\n",
    "def pad_poses(p):\n",
    "    bottom = np.broadcast_to([0, 0, 0, 1.], p[..., :1, :4].shape)\n",
    "    return np.concatenate([p[..., :3, :4], bottom], axis=-2)\n",
    "\n",
    "def get_intrinsics(json_data):\n",
    "    cam_K = np.array(json_data['cam_K']).reshape(3, 3)\n",
    "    return cam_K\n",
    "\n",
    "# single frame sparse lidar depth\n",
    "def generate_lidar_depth_seperate(datadir, camera_lidar2camera):\n",
    "    save_dir = os.path.join(datadir, 'lidar_depth_all_seperate')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    image_dir = os.path.join(datadir, 'images')\n",
    "    image_files = glob(image_dir + \"/*.jpg\") \n",
    "    image_files += glob(image_dir + \"/*.png\")\n",
    "    image_files = sorted(image_files)\n",
    "    \n",
    "\n",
    "    pointcloud_path = os.path.join(datadir, 'pointcloud_veh.npz')\n",
    "    pts3d_dict = np.load(pointcloud_path, allow_pickle=True)['pointcloud'].item()\n",
    "    pts2d_dict = np.load(pointcloud_path, allow_pickle=True)['camera_projection'].item()  \n",
    "    \n",
    "    pointcloud_path_cooperative = os.path.join(datadir, 'pointcloud_cooperative.npz')\n",
    "    pts3d_dict_coop = np.load(pointcloud_path_cooperative, allow_pickle=True)['pointcloud'].item()\n",
    "    pts2d_dict_coop = np.load(pointcloud_path_cooperative, allow_pickle=True)['camera_projection'].item()  \n",
    "    \n",
    "    pointcloud_path_inf = os.path.join(datadir, 'pointcloud_inf.npz')\n",
    "    pts3d_dict_inf = np.load(pointcloud_path_inf, allow_pickle=True)['pointcloud'].item()\n",
    "    pts2d_dict_inf = np.load(pointcloud_path_inf, allow_pickle=True)['camera_projection'].item()  \n",
    "\n",
    "    for image_filename in tqdm(image_files):\n",
    "        image = cv2.imread(image_filename)\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        image_basename = os.path.basename(image_filename)\n",
    "        frame = image_filename_to_frame(image_basename)\n",
    "        cam = image_filename_to_cam(image_basename)\n",
    "        \n",
    "        if cam == 0:\n",
    "            depth_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.npy')\n",
    "            depth_vis_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.png')\n",
    "            \n",
    "            raw_3d = pts3d_dict[frame]\n",
    "            raw_2d = pts2d_dict[frame]\n",
    "                \n",
    "            num_pts = raw_3d.shape[0]\n",
    "            pts_idx = np.arange(num_pts)\n",
    "            pts_idx = np.tile(pts_idx[..., None], (1, 2)).reshape(-1) # (num_pts * 2)\n",
    "            raw_2d = raw_2d.reshape(-1, 3) # (num_pts * 2, 3)\n",
    "            mask = (raw_2d[:, 0] == cam)\n",
    "            \n",
    "            points_xyz = raw_3d[pts_idx[mask]]\n",
    "            points_xyz = np.concatenate([points_xyz, np.ones_like(points_xyz[..., :1])], axis=-1)\n",
    "            \n",
    "            lidar2cam = camera_lidar2camera[cam][frame]\n",
    "            \n",
    "            points_xyz_cam = points_xyz @ lidar2cam.T\n",
    "            points_depth = points_xyz_cam[..., 2]\n",
    "\n",
    "            valid_mask = points_depth > 0.\n",
    "            \n",
    "            points_xyz_pixel = raw_2d[mask][:, 1:3]\n",
    "            points_coord = points_xyz_pixel[valid_mask].round().astype(np.int32)\n",
    "            points_coord[:, 0] = np.clip(points_coord[:, 0], 0, w-1)\n",
    "            points_coord[:, 1] = np.clip(points_coord[:, 1], 0, h-1)\n",
    "            \n",
    "            depth = (np.ones((h, w)) * np.finfo(np.float32).max).reshape(-1)\n",
    "            u, v = points_coord[:, 0], points_coord[:, 1]\n",
    "            indices = v * w + u\n",
    "            np.minimum.at(depth, indices, points_depth[valid_mask])\n",
    "            depth[depth >= np.finfo(np.float32).max - 1e-5] = 0\n",
    "            valid_depth_pixel = (depth != 0)\n",
    "            valid_depth_value = depth[valid_depth_pixel]\n",
    "            valid_depth_pixel = valid_depth_pixel.reshape(h, w).astype(np.bool_)\n",
    "                        \n",
    "            depth_file = dict()\n",
    "            depth_file['mask'] = valid_depth_pixel\n",
    "            depth_file['value'] = valid_depth_value\n",
    "            np.save(depth_path, depth_file)\n",
    "            \n",
    "        elif cam == 1:\n",
    "            depth_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.npy')\n",
    "            depth_vis_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.png')\n",
    "            \n",
    "            raw_3d = pts3d_dict_inf[frame]\n",
    "            raw_2d = pts2d_dict_inf[frame]\n",
    "                \n",
    "            num_pts = raw_3d.shape[0]\n",
    "            pts_idx = np.arange(num_pts)\n",
    "            pts_idx = np.tile(pts_idx[..., None], (1, 2)).reshape(-1) # (num_pts * 2)\n",
    "            raw_2d = raw_2d.reshape(-1, 3) # (num_pts * 2, 3)\n",
    "            mask = (raw_2d[:, 0] == cam)\n",
    "            \n",
    "            points_xyz = raw_3d[pts_idx[mask]]\n",
    "            points_xyz = np.concatenate([points_xyz, np.ones_like(points_xyz[..., :1])], axis=-1)\n",
    "            \n",
    "            lidar2cam = camera_lidar2camera[cam][frame]\n",
    "            \n",
    "            points_xyz_cam = points_xyz @ lidar2cam.T\n",
    "            points_depth = points_xyz_cam[..., 2]\n",
    "\n",
    "            valid_mask = points_depth > 0.\n",
    "            \n",
    "            points_xyz_pixel = raw_2d[mask][:, 1:3]\n",
    "            points_coord = points_xyz_pixel[valid_mask].round().astype(np.int32)\n",
    "            points_coord[:, 0] = np.clip(points_coord[:, 0], 0, w-1)\n",
    "            points_coord[:, 1] = np.clip(points_coord[:, 1], 0, h-1)\n",
    "            \n",
    "            depth = (np.ones((h, w)) * np.finfo(np.float32).max).reshape(-1)\n",
    "            u, v = points_coord[:, 0], points_coord[:, 1]\n",
    "            indices = v * w + u\n",
    "            np.minimum.at(depth, indices, points_depth[valid_mask])\n",
    "            depth[depth >= np.finfo(np.float32).max - 1e-5] = 0\n",
    "            valid_depth_pixel = (depth != 0)\n",
    "            valid_depth_value = depth[valid_depth_pixel]\n",
    "            valid_depth_pixel = valid_depth_pixel.reshape(h, w).astype(np.bool_)\n",
    "                        \n",
    "            depth_file = dict()\n",
    "            depth_file['mask'] = valid_depth_pixel\n",
    "            depth_file['value'] = valid_depth_value\n",
    "            np.save(depth_path, depth_file)\n",
    "\n",
    "        try:\n",
    "            depth = depth.reshape(h, w).astype(np.float32)\n",
    "            depth_vis, _ = visualize_depth_numpy(depth)\n",
    "            depth_on_img = image[..., [2, 1, 0]]\n",
    "            depth_on_img[depth > 0] = depth_vis[depth > 0]\n",
    "            cv2.imwrite(depth_vis_path, depth_on_img)      \n",
    "        except:\n",
    "            print(f'error in visualize depth of {image_filename}, depth range: {depth.min()} - {depth.max()}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{source_path}/cooperative/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "cooperative_data_info_df = pd.DataFrame(data_info_data)\n",
    "cooperative_filtered_df = cooperative_data_info_df[cooperative_data_info_df['infrastructure_sequence'] == specified_sequence_id]\n",
    "\n",
    "\n",
    "with open(f'{source_path}/infrastructure-side/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "infrastructure_data_info_df = pd.DataFrame(data_info_data)\n",
    "\n",
    "infrastructure_filtered_df = infrastructure_data_info_df[infrastructure_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "infrastructure_filtered_df = infrastructure_filtered_df.loc[infrastructure_filtered_df['frame_id'].isin(cooperative_filtered_df['infrastructure_frame'])]\n",
    "\n",
    "\n",
    "with open(f'{source_path}/vehicle-side/data_info.json', 'r') as file:\n",
    "    data_info_data = json.load(file)\n",
    "vehicle_data_info_df = pd.DataFrame(data_info_data)\n",
    "vehicle_filtered_df = vehicle_data_info_df[vehicle_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "vehicle_filtered_df = vehicle_filtered_df.loc[vehicle_filtered_df['frame_id'].isin(cooperative_filtered_df['vehicle_frame'])]\n",
    "infrastructure_calib_camera_intrinsic_paths = infrastructure_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "vehicle_calib_camera_intrinsic_paths = vehicle_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "\n",
    "car_list_infrastructure = [os.path.splitext(os.path.basename(path))[0] for path in infrastructure_calib_camera_intrinsic_paths]\n",
    "car_list_vehicle = [os.path.splitext(os.path.basename(path))[0] for path in vehicle_calib_camera_intrinsic_paths]\n",
    "\n",
    "camera_lidar2camera = [[], []]\n",
    "car_list = car_list_vehicle\n",
    "\n",
    "for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "    # CAMERA DIRECTION: RIGHT DOWN FORWARDS\n",
    "    # Read infrastructure cam info\n",
    "    infrastructure_camera_intrinsics_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'camera_intrinsic',car_list_infrastructure[idx]+'.json'))\n",
    "    infrastructure_lidar_to_camera_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_camera',car_list_infrastructure[idx]+'.json'))\n",
    "    infrastructure_lidar_to_world_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_world',car_list_infrastructure[idx]+'.json'))\n",
    "\n",
    "    # Read vehicle cam info\n",
    "    vehicle_camera_intrinsics_json = read_json_file(os.path.join(source_path,'vehicle-side', 'calib', 'camera_intrinsic', car_list_vehicle[idx] +'.json'))\n",
    "    vehicle_lidar_to_camera_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_camera', car_list_vehicle[idx] +'.json'))\n",
    "    vehicle_lidar_to_novatel_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_novatel', car_list_vehicle[idx] +'.json')) \n",
    "    vehicle_novatel_to_world_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'novatel_to_world', car_list_vehicle[idx] +'.json')) \n",
    "\n",
    "    Ks = np.array([get_intrinsics(infrastructure_camera_intrinsics_json), get_intrinsics(vehicle_camera_intrinsics_json)]) \n",
    "    lidar2cam = np.array([get_extrinsics(infrastructure_lidar_to_camera_json),get_extrinsics(vehicle_lidar_to_camera_json)])\n",
    "    lidar2world = np.array([get_extrinsics(infrastructure_lidar_to_world_json), get_extrinsics_compute_lidar_to_world(vehicle_lidar_to_novatel_json, vehicle_novatel_to_world_json)])\n",
    "    \n",
    "    novatel_to_world = get_extrinsics(vehicle_novatel_to_world_json)\n",
    "    \n",
    "    novatel_to_world_padded = pad_poses(novatel_to_world)\n",
    "\n",
    "    lidar2cam_padded = pad_poses(lidar2cam)\n",
    "    lidar2world_padded = pad_poses(lidar2world)\n",
    "    cam2lidar = np.linalg.inv(lidar2cam_padded)\n",
    "\n",
    "    c2w = lidar2world_padded @ cam2lidar\n",
    "    w2c = np.linalg.inv(c2w)\n",
    "\n",
    "    cam_road2cam_car = w2c[0] @ c2w[1]\n",
    "    cam_road2lidar_car = cam2lidar[0] @ cam_road2cam_car\n",
    "    lidar_car2cam_road = np.linalg.inv(cam_road2lidar_car)\n",
    "    \n",
    "    camera_lidar2camera[0].append(lidar2cam_padded[1])\n",
    "    camera_lidar2camera[1].append(lidar_car2cam_road)\n",
    "\n",
    "\n",
    "# destination_folder = f\"{des_path}/{specified_sequence_id}_0_original\"\n",
    "# destination_folder = \"/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0022_0_original_all_multi_lidar\"\n",
    "generate_lidar_depth_seperate(output_dir, camera_lidar2camera)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功将 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0017_0_original/lidar_depth_all_seperate' 重命名为 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0017_0_original/lidar_depth'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def rename_file_or_directory(old_path, new_path):\n",
    "    try:\n",
    "        # 检查原始路径是否存在\n",
    "        if os.path.exists(old_path):\n",
    "            # 执行重命名操作\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"已成功将 '{old_path}' 重命名为 '{new_path}'\")\n",
    "        else:\n",
    "            print(f\"路径 '{old_path}' 不存在\")\n",
    "    except FileExistsError:\n",
    "        print(f\"错误：'{new_path}' 已经存在\")\n",
    "    except PermissionError:\n",
    "        print(\"错误：没有权限执行此操作\")\n",
    "    except Exception as e:\n",
    "        print(f\"重命名时发生错误: {str(e)}\")\n",
    "\n",
    "\n",
    "old_file = output_dir + \"/lidar_depth_all_seperate\"\n",
    "new_file = output_dir + \"/lidar_depth\"\n",
    "rename_file_or_directory(old_file, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 全用的 cooperative 的 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功将 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0017_0_original/pointcloud_cooperative.npz' 重命名为 '/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0017_0_original/pointcloud.npz'\n"
     ]
    }
   ],
   "source": [
    "old_file = output_dir + \"/pointcloud_cooperative.npz\"\n",
    "new_file = output_dir + \"/pointcloud.npz\"\n",
    "rename_file_or_directory(old_file, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.getcwd())\n",
    "# import argparse\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# from lib.utils.img_utils import visualize_depth_numpy\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# image_filename_to_cam = lambda x: int(x.split('.')[0][-1])\n",
    "# image_filename_to_frame = lambda x: int(x.split('.')[0][:6])\n",
    "\n",
    "# def read_json_file(file_path):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "\n",
    "# def get_extrinsics_lidar_to_novatel(json_data):\n",
    "#     rotation = np.array(json_data['transform']['rotation'])\n",
    "#     translation = np.array(json_data['transform']['translation']).reshape(3, 1)\n",
    "#     extrinsic_matrix = np.hstack((rotation, translation))\n",
    "#     return extrinsic_matrix\n",
    "\n",
    "# def get_extrinsics(json_data):\n",
    "#     rotation = np.array(json_data['rotation'])\n",
    "#     translation = np.array(json_data['translation']).reshape(3, 1)\n",
    "#     extrinsic_matrix = np.hstack((rotation, translation))\n",
    "#     return extrinsic_matrix\n",
    "\n",
    "# def get_extrinsics_compute_lidar_to_world(lidar_to_novatel_data, novatel_to_world_data):\n",
    "#     lidar_to_novatel = get_extrinsics_lidar_to_novatel(lidar_to_novatel_data)\n",
    "#     novatel_to_world = get_extrinsics(novatel_to_world_data)\n",
    "#     lidar_to_world = np.dot(novatel_to_world, np.vstack((lidar_to_novatel, [0, 0, 0, 1])))\n",
    "    \n",
    "#     return lidar_to_world\n",
    "\n",
    "# def pad_poses(p):\n",
    "#     bottom = np.broadcast_to([0, 0, 0, 1.], p[..., :1, :4].shape)\n",
    "#     return np.concatenate([p[..., :3, :4], bottom], axis=-2)\n",
    "\n",
    "# def get_intrinsics(json_data):\n",
    "#     cam_K = np.array(json_data['cam_K']).reshape(3, 3)\n",
    "#     return cam_K\n",
    "\n",
    "# # single frame sparse lidar depth\n",
    "# def generate_lidar_depth_seperate(datadir, camera_lidar2camera):\n",
    "#     save_dir = os.path.join(datadir, 'lidar_depth_all_cooperative_2d_selection')\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     image_dir = os.path.join(datadir, 'images')\n",
    "#     image_files = glob(image_dir + \"/*.jpg\") \n",
    "#     image_files += glob(image_dir + \"/*.png\")\n",
    "#     image_files = sorted(image_files)\n",
    "    \n",
    "\n",
    "#     # pointcloud_path = os.path.join(datadir, 'pointcloud.npz')\n",
    "#     # pts3d_dict = np.load(pointcloud_path, allow_pickle=True)['pointcloud'].item()\n",
    "#     # pts2d_dict = np.load(pointcloud_path, allow_pickle=True)['camera_projection'].item()  \n",
    "    \n",
    "#     pointcloud_path_cooperative = os.path.join(datadir, 'pointcloud_cooperative.npz')\n",
    "#     pts3d_dict_coop = np.load(pointcloud_path_cooperative, allow_pickle=True)['pointcloud'].item()\n",
    "#     pts2d_dict_coop = np.load(pointcloud_path_cooperative, allow_pickle=True)['camera_projection'].item()  \n",
    "\n",
    "#     for image_filename in tqdm(image_files):\n",
    "#         image = cv2.imread(image_filename)\n",
    "#         h, w = image.shape[:2]\n",
    "        \n",
    "#         image_basename = os.path.basename(image_filename)\n",
    "#         frame = image_filename_to_frame(image_basename)\n",
    "#         cam = image_filename_to_cam(image_basename)\n",
    "        \n",
    "#         depth_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.npy')\n",
    "#         depth_vis_path = os.path.join(save_dir, f'{os.path.basename(image_filename).split(\".\")[0]}.png')\n",
    "        \n",
    "#         raw_3d = pts3d_dict_coop[frame]\n",
    "#         raw_2d = pts2d_dict_coop[frame]\n",
    "            \n",
    "#         num_pts = raw_3d.shape[0]\n",
    "#         pts_idx = np.arange(num_pts)\n",
    "#         pts_idx = np.tile(pts_idx[..., None], (1, 2)).reshape(-1) # (num_pts * 2)\n",
    "#         raw_2d = raw_2d.reshape(-1, 3) # (num_pts * 2, 3)\n",
    "#         # import pdb; pdb.set_trace()\n",
    "#         #! test\n",
    "#         mask = (raw_2d[:, 0] == cam)\n",
    "#         # mask = np.ones(raw_2d.shape[0], dtype=bool)\n",
    "        \n",
    "#         points_xyz = raw_3d[pts_idx[mask]]\n",
    "#         points_xyz = np.concatenate([points_xyz, np.ones_like(points_xyz[..., :1])], axis=-1)\n",
    "        \n",
    "#         lidar2cam = camera_lidar2camera[cam][frame]\n",
    "        \n",
    "#         points_xyz_cam = points_xyz @ lidar2cam.T\n",
    "#         points_depth = points_xyz_cam[..., 2]\n",
    "\n",
    "#         valid_mask = points_depth > 0.\n",
    "        \n",
    "#         points_xyz_pixel = raw_2d[mask][:, 1:3]\n",
    "#         points_coord = points_xyz_pixel[valid_mask].round().astype(np.int32)\n",
    "#         points_coord[:, 0] = np.clip(points_coord[:, 0], 0, w-1)\n",
    "#         points_coord[:, 1] = np.clip(points_coord[:, 1], 0, h-1)\n",
    "        \n",
    "#         depth = (np.ones((h, w)) * np.finfo(np.float32).max).reshape(-1)\n",
    "#         u, v = points_coord[:, 0], points_coord[:, 1]\n",
    "#         indices = v * w + u\n",
    "#         np.minimum.at(depth, indices, points_depth[valid_mask])\n",
    "#         depth[depth >= np.finfo(np.float32).max - 1e-5] = 0\n",
    "#         valid_depth_pixel = (depth != 0)\n",
    "#         valid_depth_value = depth[valid_depth_pixel]\n",
    "#         valid_depth_pixel = valid_depth_pixel.reshape(h, w).astype(np.bool_)\n",
    "                    \n",
    "#         depth_file = dict()\n",
    "#         depth_file['mask'] = valid_depth_pixel\n",
    "#         depth_file['value'] = valid_depth_value\n",
    "#         np.save(depth_path, depth_file)\n",
    "\n",
    "#         try:\n",
    "#             depth = depth.reshape(h, w).astype(np.float32)\n",
    "#             depth_vis, _ = visualize_depth_numpy(depth)\n",
    "#             depth_on_img = image[..., [2, 1, 0]]\n",
    "#             depth_on_img[depth > 0] = depth_vis[depth > 0]\n",
    "#             cv2.imwrite(depth_vis_path, depth_on_img)      \n",
    "#         except:\n",
    "#             print(f'error in visualize depth of {image_filename}, depth range: {depth.min()} - {depth.max()}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 167it [00:00, 990.93it/s]\n",
      "100%|██████████| 334/334 [00:54<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# with open(f'{source_path}/cooperative/data_info.json', 'r') as file:\n",
    "#     data_info_data = json.load(file)\n",
    "# cooperative_data_info_df = pd.DataFrame(data_info_data)\n",
    "# cooperative_filtered_df = cooperative_data_info_df[cooperative_data_info_df['infrastructure_sequence'] == specified_sequence_id]\n",
    "\n",
    "\n",
    "# with open(f'{source_path}/infrastructure-side/data_info.json', 'r') as file:\n",
    "#     data_info_data = json.load(file)\n",
    "# infrastructure_data_info_df = pd.DataFrame(data_info_data)\n",
    "\n",
    "# infrastructure_filtered_df = infrastructure_data_info_df[infrastructure_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "# infrastructure_filtered_df = infrastructure_filtered_df.loc[infrastructure_filtered_df['frame_id'].isin(cooperative_filtered_df['infrastructure_frame'])]\n",
    "\n",
    "\n",
    "# with open(f'{source_path}/vehicle-side/data_info.json', 'r') as file:\n",
    "#     data_info_data = json.load(file)\n",
    "# vehicle_data_info_df = pd.DataFrame(data_info_data)\n",
    "# vehicle_filtered_df = vehicle_data_info_df[vehicle_data_info_df['sequence_id'] == specified_sequence_id]\n",
    "# vehicle_filtered_df = vehicle_filtered_df.loc[vehicle_filtered_df['frame_id'].isin(cooperative_filtered_df['vehicle_frame'])]\n",
    "# infrastructure_calib_camera_intrinsic_paths = infrastructure_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "# vehicle_calib_camera_intrinsic_paths = vehicle_filtered_df['calib_camera_intrinsic_path'].tolist()\n",
    "\n",
    "# car_list_infrastructure = [os.path.splitext(os.path.basename(path))[0] for path in infrastructure_calib_camera_intrinsic_paths]\n",
    "# car_list_vehicle = [os.path.splitext(os.path.basename(path))[0] for path in vehicle_calib_camera_intrinsic_paths]\n",
    "\n",
    "# camera_lidar2camera = [[], []]\n",
    "# car_list = car_list_vehicle\n",
    "\n",
    "# for idx, car_id in tqdm(enumerate(car_list), desc=\"Loading data\"):\n",
    "#     # CAMERA DIRECTION: RIGHT DOWN FORWARDS\n",
    "#     # Read infrastructure cam info\n",
    "#     infrastructure_camera_intrinsics_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'camera_intrinsic',car_list_infrastructure[idx]+'.json'))\n",
    "#     infrastructure_lidar_to_camera_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_camera',car_list_infrastructure[idx]+'.json'))\n",
    "#     infrastructure_lidar_to_world_json = read_json_file(os.path.join(source_path,'infrastructure-side', 'calib', 'virtuallidar_to_world',car_list_infrastructure[idx]+'.json'))\n",
    "\n",
    "#     # Read vehicle cam info\n",
    "#     vehicle_camera_intrinsics_json = read_json_file(os.path.join(source_path,'vehicle-side', 'calib', 'camera_intrinsic', car_list_vehicle[idx] +'.json'))\n",
    "#     vehicle_lidar_to_camera_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_camera', car_list_vehicle[idx] +'.json'))\n",
    "#     vehicle_lidar_to_novatel_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'lidar_to_novatel', car_list_vehicle[idx] +'.json')) \n",
    "#     vehicle_novatel_to_world_json = read_json_file(os.path.join(source_path, 'vehicle-side','calib', 'novatel_to_world', car_list_vehicle[idx] +'.json')) \n",
    "\n",
    "#     Ks = np.array([get_intrinsics(infrastructure_camera_intrinsics_json), get_intrinsics(vehicle_camera_intrinsics_json)]) \n",
    "#     lidar2cam = np.array([get_extrinsics(infrastructure_lidar_to_camera_json),get_extrinsics(vehicle_lidar_to_camera_json)])\n",
    "#     lidar2world = np.array([get_extrinsics(infrastructure_lidar_to_world_json), get_extrinsics_compute_lidar_to_world(vehicle_lidar_to_novatel_json, vehicle_novatel_to_world_json)])\n",
    "    \n",
    "#     novatel_to_world = get_extrinsics(vehicle_novatel_to_world_json)\n",
    "    \n",
    "#     novatel_to_world_padded = pad_poses(novatel_to_world)\n",
    "\n",
    "#     lidar2cam_padded = pad_poses(lidar2cam)\n",
    "#     lidar2world_padded = pad_poses(lidar2world)\n",
    "#     cam2lidar = np.linalg.inv(lidar2cam_padded)\n",
    "\n",
    "#     c2w = lidar2world_padded @ cam2lidar\n",
    "#     w2c = np.linalg.inv(c2w)\n",
    "\n",
    "#     cam_road2cam_car = w2c[0] @ c2w[1]\n",
    "#     cam_road2lidar_car = cam2lidar[0] @ cam_road2cam_car\n",
    "#     lidar_car2cam_road = np.linalg.inv(cam_road2lidar_car)\n",
    "    \n",
    "#     camera_lidar2camera[0].append(lidar2cam_padded[1])\n",
    "#     camera_lidar2camera[1].append(lidar_car2cam_road)\n",
    "\n",
    "\n",
    "# # destination_folder = f\"{des_path}/{specified_sequence_id}_0_original\"\n",
    "# # destination_folder = \"/mnt/zhangsn/data/V2X-Seq-SPD-Processed/0022_0_original_all_multi_lidar\"\n",
    "# generate_lidar_depth_seperate(output_dir, camera_lidar2camera)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cruise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
